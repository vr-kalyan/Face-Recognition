# -*- coding: utf-8 -*-
"""Copy of Face Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c66BlZLjtzLovp7_RSYEHrKTrMZE8wIm

upload the images files as zip.
"""

from google.colab import files
uploaded = files.upload()

import os
for fname in uploaded.keys():
    print("Uploaded filename:", fname)

uploaded.keys()  # This will print uploaded filenames

import zipfile

zip_path = "/content/face_images.zip"  # Make sure this path is correct
extract_path = "/content/face_dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Extraction completed.")

import os

for folder in os.listdir(extract_path):
    print(folder)

"""Train the model with the face images."""

import os
import zipfile
import shutil
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Step 1: Upload ZIP (if not already uploaded)
# files.upload()  # Only run if needed

# Step 2: Paths
zip_path = "/content/face_images.zip"
extract_path = "/content/face_dataset"

# Step 3: Remove old folder if exists and extract again
shutil.rmtree(extract_path, ignore_errors=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Step 4: Define dataset path
data_dir = os.path.join(extract_path, "face_images")  # make sure subfolder exists here

# Step 5: Image Parameters
img_height, img_width = 100, 100
batch_size = 32

# Step 6: Data generators
datagen = ImageDataGenerator(
    rescale=1.0 / 255,
    validation_split=0.2  # 80% train, 20% val
)

train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

# Step 7: Model
num_classes = train_generator.num_classes

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Step 8: Compile
model.compile(optimizer=Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Step 9: Train
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10
)

# Plot training & validation accuracy and loss
import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))

plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend()
plt.title('Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend()
plt.title('Loss')

plt.show()

# Extract final epoch metrics
final_train_acc = history.history['accuracy'][-1]
final_val_acc = history.history['val_accuracy'][-1]
final_train_loss = history.history['loss'][-1]
final_val_loss = history.history['val_loss'][-1]

# Print results
print(f"Final Training Accuracy: {final_train_acc * 100:.2f}%")
print(f"Final Validation Accuracy: {final_val_acc * 100:.2f}%")
print(f"Final Training Loss: {final_train_loss:.4f}")
print(f"Final Validation Loss: {final_val_loss:.4f}")

model.save("face_recognition_model.keras")

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
import os
from google.colab import files

# Upload a test image
uploaded = files.upload()
filename = next(iter(uploaded))
img_path = "/content/" + filename

# Load and preprocess the test image
test_img = image.load_img(img_path, target_size=(img_height, img_width))
test_img_array = image.img_to_array(test_img)
test_img_array = np.expand_dims(test_img_array, axis=0) / 255.0

# Predict the label
pred = model.predict(test_img_array)
predicted_class_index = np.argmax(pred)
class_labels = list(train_generator.class_indices.keys())
predicted_label = class_labels[predicted_class_index]

# Path to one image from the predicted class folder
dataset_base_path = train_generator.directory
predicted_class_path = os.path.join(dataset_base_path, predicted_label)
representative_image_path = os.path.join(predicted_class_path, os.listdir(predicted_class_path)[0])

# Load the representative image
rep_img = image.load_img(representative_image_path, target_size=(img_height, img_width))

# Plot test image and predicted representative image side by side
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.imshow(test_img)
plt.title("Uploaded Test Image")
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(rep_img)
plt.title(f"Predicted: {predicted_label}")
plt.axis('off')

plt.show()